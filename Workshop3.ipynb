{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Neccessary Libraries",
   "id": "30a5c1238dd34089"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-08T09:51:30.241852Z",
     "start_time": "2026-01-08T09:51:29.682276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "1949b043c1ea92bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nitro\n",
      "[nltk_data]     V15\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Nitro\n",
      "[nltk_data]     V15\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Nitro\n",
      "[nltk_data]     V15\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "4cef3cfe27ddd5e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:51:30.287562Z",
     "start_time": "2026-01-08T09:51:30.254646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df = df.rename(columns={'v1': 'label', 'v2': 'text'})\n",
    "df = df[['label', 'text']]"
   ],
   "id": "69c85c59b40d785c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocess Text",
   "id": "e2230da4030e6419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:51:56.992826Z",
     "start_time": "2026-01-08T09:51:30.299403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "print(f\"Original row count: {len(df)}\")\n",
    "df['is_en'] = df['text'].apply(is_english)\n",
    "df = df[df['is_en'] == True].drop(columns=['is_en'])\n",
    "print(f\"Row count after removing non-English: {len(df)}\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "df['text2'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "df = df[df['text2'] != \"\"]"
   ],
   "id": "41734f95707edcd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 5572\n",
      "Row count after removing non-English: 5043\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Engineering",
   "id": "dee1c1e97dc0a695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:52:44.161775Z",
     "start_time": "2026-01-08T09:51:57.010661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def feature_engineering(text):\n",
    "    doc = nlp(text)\n",
    "    total_tokens = len(doc)\n",
    "\n",
    "    if total_tokens == 0:\n",
    "        return pd.Series([0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    nouns = len([token for token in doc if token.pos_ == \"NOUN\"])\n",
    "    verbs = len([token for token in doc if token.pos_ == \"VERB\"])\n",
    "    adjs  = len([token for token in doc if token.pos_ == \"ADJ\"])\n",
    "\n",
    "    noun_ratio = nouns / total_tokens\n",
    "    verb_ratio = verbs / total_tokens\n",
    "    adj_ratio  = adjs / total_tokens\n",
    "\n",
    "    avg_token_len = sum(len(token.text) for token in doc) / total_tokens if total_tokens > 0 else 0\n",
    "\n",
    "    unique_pos = len(set([token.pos_ for token in doc]))\n",
    "    pos_diversity = unique_pos / total_tokens\n",
    "\n",
    "    length = total_tokens\n",
    "\n",
    "    return pd.Series([length, noun_ratio, verb_ratio, adj_ratio, avg_token_len, pos_diversity])\n",
    "\n",
    "print(\"Processing calculate_text_stats...\")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df[['length', 'noun_ratio', 'verb_ratio', 'adj_ratio', 'avg_token_len', 'pos_diversity']] = df['text2'].apply(feature_engineering)"
   ],
   "id": "8395b51783ca2a3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing calculate_text_stats...\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformation",
   "id": "61802c6092794929"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:52:44.194645Z",
     "start_time": "2026-01-08T09:52:44.176916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_norm = ['length', 'noun_ratio', 'verb_ratio', 'adj_ratio', 'avg_token_len', 'pos_diversity']\n",
    "df[cols_to_norm] = scaler.fit_transform(df[cols_to_norm])"
   ],
   "id": "a3e210dd1b04a338",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## BOW & Final Output",
   "id": "2b8137f540f1e3a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:52:44.431583Z",
     "start_time": "2026-01-08T09:52:44.216992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv = CountVectorizer(max_features=300)\n",
    "bow_matrix = cv.fit_transform(df['text2']).toarray()\n",
    "bow_df = pd.DataFrame(bow_matrix, columns=cv.get_feature_names_out())\n",
    "\n",
    "final_df = pd.concat([df[cols_to_norm], df[['label_encoded']], bow_df], axis=1)\n",
    "\n",
    "print(f\"Final Data Shape: {final_df.shape}\")\n",
    "\n",
    "print(\"\\n--- Top 5 Samples ---\")\n",
    "display(final_df.head(5))\n",
    "\n",
    "print(\"\\n--- Bottom 5 Samples ---\")\n",
    "display(final_df.tail(5))"
   ],
   "id": "aafedeca3d84802d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data Shape: (5040, 307)\n",
      "\n",
      "--- Top 5 Samples ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     length  noun_ratio  verb_ratio  adj_ratio  avg_token_len  pos_diversity  \\\n",
       "0  0.182927    0.187500    0.125000   0.125000       0.080023       0.312500   \n",
       "1  0.231707    0.350000    0.200000   0.100000       0.085981       0.175000   \n",
       "2  0.097561    0.222222    0.222222   0.111111       0.046729       0.633333   \n",
       "3  0.097561    0.111111    0.222222   0.111111       0.074766       0.755556   \n",
       "4  0.207317    0.333333    0.111111   0.000000       0.063863       0.266667   \n",
       "\n",
       "   label_encoded  account  actually  aight  ...  would  xxx  ya  yeah  year  \\\n",
       "0              0        0         0      0  ...      0    0   0     0     0   \n",
       "1              1        0         0      0  ...      0    0   0     0     0   \n",
       "2              0        0         0      0  ...      0    0   0     0     0   \n",
       "3              0        0         0      0  ...      0    0   0     0     0   \n",
       "4              1        0         0      0  ...      0    1   0     0     0   \n",
       "\n",
       "   yes  yet  yo  youre  yup  \n",
       "0    0    0   0      0    0  \n",
       "1    0    0   0      0    0  \n",
       "2    0    0   0      0    0  \n",
       "3    0    0   0      0    0  \n",
       "4    0    0   0      0    0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adj_ratio</th>\n",
       "      <th>avg_token_len</th>\n",
       "      <th>pos_diversity</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>aight</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>xxx</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>youre</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.182927</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.080023</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bottom 5 Samples ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        length  noun_ratio  verb_ratio  adj_ratio  avg_token_len  \\\n",
       "5035  0.170732    0.666667    0.066667   0.066667       0.087850   \n",
       "5036  0.048780    0.400000    0.200000   0.000000       0.080374   \n",
       "5037  0.036585    0.750000    0.000000   0.250000       0.130841   \n",
       "5038  0.170732    0.266667    0.200000   0.266667       0.091589   \n",
       "5039  0.024390    0.333333    0.333333   0.333333       0.074766   \n",
       "\n",
       "      pos_diversity  label_encoded  account  actually  aight  ...  would  xxx  \\\n",
       "5035           0.34              1        0         0      0  ...      0    0   \n",
       "5036           0.78              0        0         0      0  ...      0    0   \n",
       "5037           0.45              0        0         0      0  ...      0    0   \n",
       "5038           0.34              0        0         0      0  ...      0    0   \n",
       "5039           1.00              0        0         0      0  ...      0    0   \n",
       "\n",
       "      ya  yeah  year  yes  yet  yo  youre  yup  \n",
       "5035   0     0     0    0    0   0      0    0  \n",
       "5036   0     0     0    0    0   0      0    0  \n",
       "5037   0     0     0    0    0   0      0    0  \n",
       "5038   0     0     0    0    0   0      0    0  \n",
       "5039   0     0     0    0    0   0      0    0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adj_ratio</th>\n",
       "      <th>avg_token_len</th>\n",
       "      <th>pos_diversity</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>aight</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>xxx</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>youre</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.087850</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.130841</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.091589</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train & Test KNN Model",
   "id": "cd9d51cf16652642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:52:45.275460Z",
     "start_time": "2026-01-08T09:52:44.575813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X = final_df.drop(columns=['label_encoded'])\n",
    "y = final_df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "print(\"Training KNN model...\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "436f9b28f25848ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3528, 306)\n",
      "Test set shape: (1512, 306)\n",
      "Training KNN model...\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9511\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1300\n",
      "           1       0.96      0.68      0.80       212\n",
      "\n",
      "    accuracy                           0.95      1512\n",
      "   macro avg       0.96      0.84      0.88      1512\n",
      "weighted avg       0.95      0.95      0.95      1512\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
